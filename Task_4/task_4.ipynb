{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание - решение задачи регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Загрузка и исследование набора данных\n",
    "###### Загрузите набор данных и изучите его: объем выборки, количество столбцов, характеристики столбцов (признаков), имеются ли пропуски, имеются ли выбросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1303 entries, 0 to 1302\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   laptop_ID         1303 non-null   int64  \n",
      " 1   Company           1303 non-null   object \n",
      " 2   Product           1303 non-null   object \n",
      " 3   TypeName          1303 non-null   object \n",
      " 4   Inches            1303 non-null   float64\n",
      " 5   ScreenResolution  1303 non-null   object \n",
      " 6   Cpu               1303 non-null   object \n",
      " 7   Ram               1303 non-null   object \n",
      " 8   Memory            1303 non-null   object \n",
      " 9   Gpu               1303 non-null   object \n",
      " 10  OpSys             1303 non-null   object \n",
      " 11  Weight            1303 non-null   object \n",
      " 12  Price_euros       1303 non-null   float64\n",
      "dtypes: float64(2), int64(1), object(10)\n",
      "memory usage: 132.5+ KB\n",
      "None\n",
      "         laptop_ID       Inches  Price_euros\n",
      "count  1303.000000  1303.000000  1303.000000\n",
      "mean    660.155794    15.017191  1123.686992\n",
      "std     381.172104     1.426304   699.009043\n",
      "min       1.000000    10.100000   174.000000\n",
      "25%     331.500000    14.000000   599.000000\n",
      "50%     659.000000    15.600000   977.000000\n",
      "75%     990.500000    15.600000  1487.880000\n",
      "max    1320.000000    18.400000  6099.000000\n",
      "laptop_ID           0\n",
      "Company             0\n",
      "Product             0\n",
      "TypeName            0\n",
      "Inches              0\n",
      "ScreenResolution    0\n",
      "Cpu                 0\n",
      "Ram                 0\n",
      "Memory              0\n",
      "Gpu                 0\n",
      "OpSys               0\n",
      "Weight              0\n",
      "Price_euros         0\n",
      "dtype: int64\n",
      "Уникальные значения в столбце Company: ['Apple' 'HP' 'Acer' 'Asus' 'Dell']...\n",
      "Уникальные значения в столбце Product: ['MacBook Pro' 'Macbook Air' '250 G6' 'Aspire 3' 'ZenBook UX430UN']...\n",
      "Уникальные значения в столбце TypeName: ['Ultrabook' 'Notebook' 'Netbook' 'Gaming' '2 in 1 Convertible']...\n",
      "Уникальные значения в столбце ScreenResolution: ['IPS Panel Retina Display 2560x1600' '1440x900' 'Full HD 1920x1080'\n",
      " 'IPS Panel Retina Display 2880x1800' '1366x768']...\n",
      "Уникальные значения в столбце Cpu: ['Intel Core i5 2.3GHz' 'Intel Core i5 1.8GHz'\n",
      " 'Intel Core i5 7200U 2.5GHz' 'Intel Core i7 2.7GHz'\n",
      " 'Intel Core i5 3.1GHz']...\n",
      "Уникальные значения в столбце Ram: ['8GB' '16GB' '4GB' '2GB' '12GB']...\n",
      "Уникальные значения в столбце Memory: ['128GB SSD' '128GB Flash Storage' '256GB SSD' '512GB SSD' '500GB HDD']...\n",
      "Уникальные значения в столбце Gpu: ['Intel Iris Plus Graphics 640' 'Intel HD Graphics 6000'\n",
      " 'Intel HD Graphics 620' 'AMD Radeon Pro 455'\n",
      " 'Intel Iris Plus Graphics 650']...\n",
      "Уникальные значения в столбце OpSys: ['macOS' 'No OS' 'Windows 10' 'Mac OS X' 'Linux']...\n",
      "Уникальные значения в столбце Weight: ['1.37kg' '1.34kg' '1.86kg' '1.83kg' '2.1kg']...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('laptop_price.csv', encoding='windows-1251')\n",
    "\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df.isnull().sum())\n",
    "\n",
    "object_columns = ['Company', 'Product', 'TypeName', 'ScreenResolution', 'Cpu', 'Ram', 'Memory', 'Gpu', 'OpSys', 'Weight']\n",
    "for column in object_columns:\n",
    "    print(f\"Уникальные значения в столбце {column}: {df[column].unique()[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Предобработка данных\n",
    "###### Подумайте как преобразовать столбцы, чтобы привести все к числовому виду: где стоит категории заменить метками, где преобразовать ###### столбцы. Для этого у всех столбцов типа object посмотрите уникальные значения. \n",
    "\n",
    "###### Столбцы типа данных object ['Company', 'Product', 'TypeName', 'ScreenResolution', 'Cpu', 'Ram', 'Memory', 'Gpu', 'OpSys', 'Weight']\n",
    "###### Рекомендации:\n",
    "###### - столбец 'Product' можно удалить, в нем  618 уникальных значений\n",
    "###### - для столбцов 'RAM'  и 'Weight'  оставить только цифры - объем памяти  и вес, причем в каждом столбце числа должны соответствовать одинаковым единицам Gb и kg\n",
    "###### - столбец Memory стоит преобразовать к нескольким столбцам, соответствующим Memory_SSD, Memory_HDD, Memory_Flash_Storage, Memory_Hybrid все объемы памяти перевести в GB и записать в соответствующие столбцы\n",
    "###### - решите что делать с остальными столбцами, обосновывая свои решения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['128GB SSD', '128GB Flash Storage', '256GB SSD', '512GB SSD',\n",
       "       '500GB HDD', '256GB Flash Storage', '1TB HDD',\n",
       "       '32GB Flash Storage', '128GB SSD +  1TB HDD',\n",
       "       '256GB SSD +  256GB SSD', '64GB Flash Storage',\n",
       "       '256GB SSD +  1TB HDD', '256GB SSD +  2TB HDD', '32GB SSD',\n",
       "       '2TB HDD', '64GB SSD', '1.0TB Hybrid', '512GB SSD +  1TB HDD',\n",
       "       '1TB SSD', '256GB SSD +  500GB HDD', '128GB SSD +  2TB HDD',\n",
       "       '512GB SSD +  512GB SSD', '16GB SSD', '16GB Flash Storage',\n",
       "       '512GB SSD +  256GB SSD', '512GB SSD +  2TB HDD',\n",
       "       '64GB Flash Storage +  1TB HDD', '180GB SSD', '1TB HDD +  1TB HDD',\n",
       "       '32GB HDD', '1TB SSD +  1TB HDD', '512GB Flash Storage',\n",
       "       '128GB HDD', '240GB SSD', '8GB SSD', '508GB Hybrid', '1.0TB HDD',\n",
       "       '512GB SSD +  1.0TB Hybrid', '256GB SSD +  1.0TB Hybrid'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Memory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      laptop_ID Company TypeName  Inches ScreenResolution   Cpu  Ram   Gpu  \\\n",
      "21           22    10.0      1.0    15.6             15.0  65.0    8  67.0   \n",
      "37           38     4.0      3.0    17.3             15.0  71.0    8   6.0   \n",
      "41           42     4.0      1.0    15.6             15.0  90.0   16  71.0   \n",
      "47           48     2.0      1.0    17.3              8.0  21.0    8  32.0   \n",
      "58           59    11.0      1.0    17.3              8.0  90.0   16  72.0   \n",
      "...         ...     ...      ...     ...              ...   ...  ...   ...   \n",
      "1238       1256    11.0      1.0    15.6              8.0  80.0    8  81.0   \n",
      "1245       1263     2.0      1.0    15.6             15.0  90.0   16  68.0   \n",
      "1247       1265     2.0      1.0    15.6             15.0  80.0   16  72.0   \n",
      "1256       1274     2.0      1.0    17.3             15.0  80.0   16  83.0   \n",
      "1259       1277    11.0      1.0    15.6              8.0  80.0    8  81.0   \n",
      "\n",
      "     OpSys  Weight  Price_euros  Memory_SSD  Memory_HDD  Memory_Flash_Storage  \\\n",
      "21     5.0    2.50        999.0         128        1024                     0   \n",
      "37     5.0    2.80        979.0         128        1024                     0   \n",
      "41     5.0    2.65       1499.0         256        1024                     0   \n",
      "47     5.0    3.20       1299.0         256        1024                     0   \n",
      "58     5.0    2.43       2449.0         256        2048                     0   \n",
      "...    ...     ...          ...         ...         ...                   ...   \n",
      "1238   5.0    2.30       1169.0         128        1024                     0   \n",
      "1245   5.0    2.50       1600.0         256        1024                     0   \n",
      "1247   5.0    2.34       2325.0         256        1024                     0   \n",
      "1256   5.0    4.00       1900.0         128        1024                     0   \n",
      "1259   5.0    2.40       1229.0         128        1024                     0   \n",
      "\n",
      "      Memory_Hybrid  \n",
      "21                0  \n",
      "37                0  \n",
      "41                0  \n",
      "47                0  \n",
      "58                0  \n",
      "...             ...  \n",
      "1238              0  \n",
      "1245              0  \n",
      "1247              0  \n",
      "1256              0  \n",
      "1259              0  \n",
      "\n",
      "[202 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "df.drop('Product', axis=1, inplace=True)\n",
    "\n",
    "df['Ram'] = df['Ram'].str.replace('GB', '').astype(int)\n",
    "df['Weight'] = df['Weight'].str.replace('kg', '').astype(float)\n",
    "\n",
    "def process_memory(memory):\n",
    "    ssd, hdd, flash, hybrid = 0, 0, 0, 0\n",
    "    for part in memory.split('+'):\n",
    "        part = part.strip()\n",
    "        size_match = re.search(r'(\\d+)', part)\n",
    "        type_match = re.search(r'(SSD|HDD|Flash Storage|Hybrid)', part)\n",
    "        \n",
    "        if size_match and type_match:\n",
    "            size = int(size_match.group(1))\n",
    "            if 'TB' in part:\n",
    "                size *= 1024\n",
    "            \n",
    "            memory_type = type_match.group(1)\n",
    "            if memory_type == 'SSD':\n",
    "                ssd += size\n",
    "            elif memory_type == 'HDD':\n",
    "                hdd += size\n",
    "            elif memory_type == 'Flash Storage':\n",
    "                flash += size\n",
    "            elif memory_type == 'Hybrid':\n",
    "                hybrid += size\n",
    "\n",
    "    return pd.Series([ssd, hdd, flash, hybrid])\n",
    "\n",
    "df[['Memory_SSD', 'Memory_HDD', 'Memory_Flash_Storage', 'Memory_Hybrid']] = df['Memory'].apply(process_memory)\n",
    "df.drop('Memory', axis=1, inplace=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "categorical_columns = ['Company', 'TypeName', 'ScreenResolution', 'Cpu', 'Gpu', 'OpSys']\n",
    "\n",
    "train_splits = {}\n",
    "test_splits = {}\n",
    "encoders = {}\n",
    "\n",
    "for column in categorical_columns:\n",
    "    X_train, X_test = train_test_split(df[[column]], test_size=0.2, random_state=42)\n",
    "    \n",
    "    encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    X_train_encoded = encoder.fit_transform(X_train)\n",
    "    X_test_encoded = encoder.transform(X_test)\n",
    "    \n",
    "    train_splits[column] = X_train_encoded\n",
    "    test_splits[column] = X_test_encoded\n",
    "    encoders[column] = encoder\n",
    "\n",
    "    df.loc[X_train.index, column] = X_train_encoded.flatten()\n",
    "    df.loc[X_test.index, column] = X_test_encoded.flatten()\n",
    "    \n",
    "\n",
    "df_multiple_memory_types = df[\n",
    "    (df['Memory_SSD'] > 0) & \n",
    "    ((df['Memory_HDD'] > 0) | (df['Memory_Flash_Storage'] > 0) | (df['Memory_Hybrid'] > 0))\n",
    "]\n",
    "\n",
    "print(df_multiple_memory_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Столбец laptop_ID  не несет смысловой информации его удалите\n",
    "\n",
    "\n",
    "##### 4. Сделайте три копии  датасета:  df, df_mm, df_ss. Следующие действия проделайте с каждой из копий:\n",
    "\n",
    "###### Отделите целевой столбец от нецелевых\n",
    "\n",
    "###### Разделите данные на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "df_mm = df.copy()\n",
    "df_ss = df.copy()\n",
    "\n",
    "X = df.drop(['Price_euros', 'laptop_ID'], axis=1)\n",
    "y = df['Price_euros']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler_mm = MinMaxScaler()\n",
    "X_train_mm = scaler_mm.fit_transform(X_train)\n",
    "X_test_mm = scaler_mm.transform(X_test)\n",
    "\n",
    "scaler_ss = StandardScaler()\n",
    "X_train_ss = scaler_ss.fit_transform(X_train)\n",
    "X_test_ss = scaler_ss.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        'Train MSE': mean_squared_error(y_train, y_train_pred),\n",
    "        'Test MSE': mean_squared_error(y_test, y_test_pred),\n",
    "        'Train R2': r2_score(y_train, y_train_pred),\n",
    "        'Test R2': r2_score(y_test, y_test_pred)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso Regression\": Lasso(alpha=0.1),\n",
    "    \"Ridge Regression\": Ridge(alpha=0.1)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    results[model_name] = {\n",
    "        'Original': evaluate_model(model, X_train, y_train, X_test, y_test),\n",
    "        'MinMax Scaled': evaluate_model(model, X_train_mm, y_train, X_test_mm, y_test),\n",
    "        'Standard Scaled': evaluate_model(model, X_train_ss, y_train, X_test_ss, y_test)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Полиномиальная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "for degree in [2, 3]:\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "    poly_model = Ridge(alpha=3)\n",
    "    poly_metrics = evaluate_model(poly_model, X_train_poly, y_train, X_test_poly, y_test)\n",
    "\n",
    "    results[f'Polynomial Regression (Degree {degree})'] = {\n",
    "        'Original': poly_metrics  \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Вывод результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression Results:\n",
      "  Original -> Train MSE: 138181.3576, Test MSE: 162782.3442, Train R2: 0.7140, Test R2: 0.6795\n",
      "  MinMax Scaled -> Train MSE: 138181.3576, Test MSE: 162782.3442, Train R2: 0.7140, Test R2: 0.6795\n",
      "  Standard Scaled -> Train MSE: 138181.3576, Test MSE: 162782.3442, Train R2: 0.7140, Test R2: 0.6795\n",
      "\n",
      "Lasso Regression Results:\n",
      "  Original -> Train MSE: 138181.5715, Test MSE: 162795.0976, Train R2: 0.7140, Test R2: 0.6795\n",
      "  MinMax Scaled -> Train MSE: 138191.2472, Test MSE: 162946.6446, Train R2: 0.7140, Test R2: 0.6792\n",
      "  Standard Scaled -> Train MSE: 138181.5767, Test MSE: 162795.8366, Train R2: 0.7140, Test R2: 0.6795\n",
      "\n",
      "Ridge Regression Results:\n",
      "  Original -> Train MSE: 138181.3621, Test MSE: 162783.1618, Train R2: 0.7140, Test R2: 0.6795\n",
      "  MinMax Scaled -> Train MSE: 138209.9000, Test MSE: 163164.4874, Train R2: 0.7140, Test R2: 0.6788\n",
      "  Standard Scaled -> Train MSE: 138181.3600, Test MSE: 162786.8604, Train R2: 0.7140, Test R2: 0.6795\n",
      "\n",
      "Polynomial Regression (Degree 2) Results:\n",
      "  Original -> Train MSE: 83699.9988, Test MSE: 209729.9599, Train R2: 0.8268, Test R2: 0.5871\n",
      "\n",
      "Polynomial Regression (Degree 3) Results:\n",
      "  Original -> Train MSE: 36398.0828, Test MSE: 5981927.6037, Train R2: 0.9247, Test R2: -10.7772\n"
     ]
    }
   ],
   "source": [
    "for model_name, model_results in results.items():\n",
    "    print(f'\\n{model_name} Results:')\n",
    "    for data_version, metrics in model_results.items():\n",
    "        print(f'  {data_version} -> Train MSE: {metrics[\"Train MSE\"]:.4f}, Test MSE: {metrics[\"Test MSE\"]:.4f}, Train R2: {metrics[\"Train R2\"]:.4f}, Test R2: {metrics[\"Test R2\"]:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression\n",
      "Dataset              Train MSE    Test MSE     Train R2   Test R2   \n",
      "Original             138181.3576  162782.3442  0.7140     0.6795    \n",
      "MinMax Scaled        138181.3576  162782.3442  0.7140     0.6795    \n",
      "Standard Scaled      138181.3576  162782.3442  0.7140     0.6795    \n",
      "\n",
      "Lasso Regression\n",
      "Dataset              Train MSE    Test MSE     Train R2   Test R2   \n",
      "Original             138181.5715  162795.0976  0.7140     0.6795    \n",
      "MinMax Scaled        138191.2472  162946.6446  0.7140     0.6792    \n",
      "Standard Scaled      138181.5767  162795.8366  0.7140     0.6795    \n",
      "\n",
      "Ridge Regression\n",
      "Dataset              Train MSE    Test MSE     Train R2   Test R2   \n",
      "Original             138181.3621  162783.1618  0.7140     0.6795    \n",
      "MinMax Scaled        138209.9000  163164.4874  0.7140     0.6788    \n",
      "Standard Scaled      138181.3600  162786.8604  0.7140     0.6795    \n",
      "\n",
      "Polynomial Regression (Degree 2)\n",
      "Dataset              Train MSE    Test MSE     Train R2   Test R2   \n",
      "Original                83699.9988   209729.9599  0.8268     0.5871    \n",
      "\n",
      "Polynomial Regression (Degree 3)\n",
      "Dataset              Train MSE    Test MSE     Train R2   Test R2   \n",
      "Original                36398.0828   5981927.6037 0.9247     -10.7772  \n"
     ]
    }
   ],
   "source": [
    "def display_results():\n",
    "    for model_name in [\"Linear Regression\", \"Lasso Regression\", \"Ridge Regression\"]:\n",
    "        print(f'\\n{model_name}')\n",
    "        print(f\"{'Dataset':<20} {'Train MSE':<12} {'Test MSE':<12} {'Train R2':<10} {'Test R2':<10}\")\n",
    "        for data_version, metrics in results[model_name].items():\n",
    "            print(f\"{data_version:<20} {metrics['Train MSE']:<12.4f} {metrics['Test MSE']:<12.4f} {metrics['Train R2']:<10.4f} {metrics['Test R2']:<10.4f}\")\n",
    "\n",
    "    for degree in [2, 3]:\n",
    "        model_name = f'Polynomial Regression (Degree {degree})'\n",
    "        print(f'\\n{model_name}')\n",
    "        print(f\"{'Dataset':<20} {'Train MSE':<12} {'Test MSE':<12} {'Train R2':<10} {'Test R2':<10}\")\n",
    "        metrics = results[model_name]['Original']\n",
    "        print(f\"Original{' ' * 15} {metrics['Train MSE']:<12.4f} {metrics['Test MSE']:<12.4f} {metrics['Train R2']:<10.4f} {metrics['Test R2']:<10.4f}\")\n",
    "\n",
    "display_results()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Добро пожаловать в Colaboratory!",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
